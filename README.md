# üöÄ CrackTheInterview (English Version)

<p align="center">
  <img src="https://img.shields.io/badge/Python-3.8+-blue.svg" alt="Python Version">
  <img src="https://img.shields.io/badge/CUDA-Compatible-brightgreen.svg" alt="CUDA Compatible">
  <img src="https://img.shields.io/badge/License-MIT-yellow.svg" alt="License">
  <img src="https://img.shields.io/badge/OpenAI-GPT_Integration-orange.svg" alt="OpenAI GPT">
</p>

<p align="center">
  <b>Automated Interview Assistant powered by Whisper and GPT</b><br>
  <i>Local speech recognition and intelligent responses</i>
</p>

---

## üìã Description

**CrackTheInterview** is a Python tool that helps you succeed in interviews by using local Whisper model for speech recognition and GPT for response generation. The application runs on Windows with an NVIDIA graphics card.

<p align="center">
  <img src="image.png" alt="CrackTheInterview interface" width="80%">
</p>

## ‚ú® Features

- üéôÔ∏è Local speech recognition using Whisper
- üß† Response generation using OpenAI GPT models
- ‚ö° GPU acceleration for maximum performance
- üîÑ Audio capture from any application (Zoom, Teams, Discord, etc.)
- üõ†Ô∏è Flexible customization for specific positions and requirements

## üîß Requirements

- Windows
- NVIDIA graphics card with CUDA support
- Python 3.8+
- VB-Audio CABLE for audio capture

## üíª Installation

1. **Clone the repository:**
   ```bash
   git clone https://github.com/etosheartem/CrackTheInterview-.git
   cd CrackTheInterview-
   ```

2. **Create a virtual environment:**
   ```bash
   python -m venv myenv
   myenv\Scripts\activate
   ```

3. **Install dependencies:**
   ```bash
   python -m pip install --upgrade pip
   pip install -r requirements.txt
   ```

4. **Run the application:**
   ```bash
   python .\speech_to_text.py
   ```

## ‚öôÔ∏è Configuration

### 1. CUDA Support Check

If you see "CUDA available? False" message at startup, follow these steps:

1. Check your CUDA version:
   ```bash
   nvcc --version
   ```

2. Reinstall PyTorch with the appropriate CUDA version support:
   ```bash
   pip uninstall torch torchvision
   pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121
   ```

<details>
<summary><b>CUDA and PyTorch Version Compatibility</b></summary>

| CUDA Version | PyTorch Command |
|--------------|-----------------|
| CUDA 12.8    | `pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121` |
| CUDA 12.1    | `pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121` |
| CUDA 11.7    | `pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu117` |
| CUDA 11.3    | `pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu113` |
| CUDA 10.2    | `pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu102` |

</details>

### 2. Whisper Configuration

In `speech_to_text.py`, configure the Whisper model:

```python
model = whisper.load_model("large-v3-turbo", device="cuda")
```

<details>
<summary><b>Available Whisper Models</b></summary>

- **tiny**: The most compact model with minimal accuracy and maximum speed
- **base**: Small model with basic accuracy
- **small**: Medium-sized model with a good balance of speed and accuracy
- **medium**: Advanced model for complex recognition tasks
- **large-v2**: Large model with high accuracy (2022)
- **large-v3**: Improved version with enhanced accuracy
- **large-v3-turbo**: Optimized version for fast operation (recommended for RTX 3070 Ti)

</details>

### 3. OpenAI API Setup

1. Provide your OpenAI API key in `speech_to_text.py` (line 35)
2. Select your preferred model:
   ```python
   model="gpt-4o-mini"  # Recommended for most tasks
   ```

### 4. Prompt Customization

Edit the prompt for your specific position:

```python
{"role": "system", "content": "This is an interview for the position of ***Job Title***. You should answer questions concisely and clearly in English. You should not ask questions, only answer them."},
{"role": "user", "content": f"Process the following text, it may contain errors, ignore them or infer the answer: {text}"}
```

### 5. Audio Capture Setup

1. Download and install [VB-Audio CABLE](https://vb-audio.com/Cable/)

2. **Detailed configuration:**
   1. Right-click on the sound icon in the system tray and select "Open Volume Mixer"
   2. Select the application from which you want to capture audio (Telegram/Zoom/browser, etc.)
      - Using Google Chrome as an example: to display it, there must be sound coming from it (play a video or music)
      - Output device: CABLE Input
      - Input device: default
   
   3. To continue hearing the sound:
      - Right-click on the sound icon in the system tray
      - Select "Sound settings" ‚Üí at the very bottom "Sound control panel"
      - Go to the "Recording" tab ‚Üí "CABLE Output" ‚Üí "Listen"
      - Check "Listen to this device" and select your headphones/speakers
      - After applying the settings, you should hear sounds from the browser

3. **Verifying operation:**
   - After configuration, return to the CrackTheInterview application
   - You should now see the processed audio in the interface
   - When you select the recognized speech text, the GPT response will appear in the right window

## üîç Troubleshooting

- **Low recognition accuracy**: Try a larger model or improve audio quality
- **Slow performance**: Make sure GPU is being used (`device="cuda"`)
- **Installation errors**: Check compatibility between CUDA and PyTorch versions

## üíñ Support the Project

If you like this project, you can support the developer:

- **USDT TRC20**: `TCpmyqG8Df4SaKhinXFqfSgbmmGQw5b66K`
- **BTC**: `14nZsN8H2iWFRRHszHZRp6bk1nCxodnSZ9`


---

# üöÄ CrackTheInterview

<p align="center">
  <img src="https://img.shields.io/badge/Python-3.8+-blue.svg" alt="Python Version">
  <img src="https://img.shields.io/badge/CUDA-Compatible-brightgreen.svg" alt="CUDA Compatible">
  <img src="https://img.shields.io/badge/License-MIT-yellow.svg" alt="License">
  <img src="https://img.shields.io/badge/OpenAI-GPT_Integration-orange.svg" alt="OpenAI GPT">
</p>

<p align="center">
  <b>–ê–≤—Ç–æ–º–∞—Ç–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –ø–æ–º–æ—â–Ω–∏–∫ –¥–ª—è —Å–æ–±–µ—Å–µ–¥–æ–≤–∞–Ω–∏–π –Ω–∞ –æ—Å–Ω–æ–≤–µ Whisper –∏ GPT</b><br>
  <i>–õ–æ–∫–∞–ª—å–Ω–æ–µ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ —Ä–µ—á–∏ –∏ –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω—ã–µ –æ—Ç–≤–µ—Ç—ã</i>
</p>

---

## üìã –û–ø–∏—Å–∞–Ω–∏–µ

**CrackTheInterview** ‚Äî —ç—Ç–æ Python-–∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç, –∫–æ—Ç–æ—Ä—ã–π –ø–æ–º–æ–≥–∞–µ—Ç —É—Å–ø–µ—à–Ω–æ –ø—Ä–æ—Ö–æ–¥–∏—Ç—å —Å–æ–±–µ—Å–µ–¥–æ–≤–∞–Ω–∏—è, –∏—Å–ø–æ–ª—å–∑—É—è –ª–æ–∫–∞–ª—å–Ω—É—é –º–æ–¥–µ–ª—å Whisper –¥–ª—è —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è —Ä–µ—á–∏ –∏ GPT –¥–ª—è —Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏—è –æ—Ç–≤–µ—Ç–æ–≤. –ü—Ä–∏–ª–æ–∂–µ–Ω–∏–µ —Ä–∞–±–æ—Ç–∞–µ—Ç –Ω–∞ Windows —Å –≤–∏–¥–µ–æ–∫–∞—Ä—Ç–æ–π NVIDIA.

<p align="center">
  <img src="image.png" alt="CrackTheInterview –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å" width="80%">
</p>

## ‚ú® –í–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏

- üéôÔ∏è –õ–æ–∫–∞–ª—å–Ω–æ–µ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ —Ä–µ—á–∏ —Å –ø–æ–º–æ—â—å—é Whisper
- üß† –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–æ–≤ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –º–æ–¥–µ–ª–µ–π OpenAI GPT
- ‚ö° –†–∞–±–æ—Ç–∞ –Ω–∞ GPU –¥–ª—è –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
- üîÑ –ü–µ—Ä–µ—Ö–≤–∞—Ç –∑–≤—É–∫–∞ –∏–∑ –ª—é–±–æ–≥–æ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è (Zoom, Teams, Discord –∏ –¥—Ä.)
- üõ†Ô∏è –ì–∏–±–∫–∞—è –Ω–∞—Å—Ç—Ä–æ–π–∫–∞ –ø–æ–¥ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ –¥–æ–ª–∂–Ω–æ—Å—Ç–∏ –∏ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è

## üîß –¢—Ä–µ–±–æ–≤–∞–Ω–∏—è

- Windows
- –í–∏–¥–µ–æ–∫–∞—Ä—Ç–∞ NVIDIA —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π CUDA
- Python 3.8+
- VB-Audio CABLE –¥–ª—è –ø–µ—Ä–µ—Ö–≤–∞—Ç–∞ –∑–≤—É–∫–∞

## üíª –£—Å—Ç–∞–Ω–æ–≤–∫–∞

1. **–ö–ª–æ–Ω–∏—Ä—É–π—Ç–µ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π:**
   ```bash
   git clone https://github.com/etosheartem/CrackTheInterview-.git
   cd CrackTheInterview-
   ```

2. **–°–æ–∑–¥–∞–π—Ç–µ –≤–∏—Ä—Ç—É–∞–ª—å–Ω–æ–µ –æ–∫—Ä—É–∂–µ–Ω–∏–µ:**
   ```bash
   python -m venv myenv
   myenv\Scripts\activate
   ```

3. **–£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏:**
   ```bash
   python -m pip install --upgrade pip
   pip install -r requirements.txt
   ```

4. **–ó–∞–ø—É—Å—Ç–∏—Ç–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ:**
   ```bash
   python .\speech_to_text.py
   ```

## ‚öôÔ∏è –ù–∞—Å—Ç—Ä–æ–π–∫–∞

### 1. –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ–¥–¥–µ—Ä–∂–∫–∏ CUDA

–ï—Å–ª–∏ –ø—Ä–∏ –∑–∞–ø—É—Å–∫–µ –≤—ã –≤–∏–¥–∏—Ç–µ —Å–æ–æ–±—â–µ–Ω–∏–µ "CUDA –¥–æ—Å—Ç—É–ø–Ω–∞? False", –≤—ã–ø–æ–ª–Ω–∏—Ç–µ —Å–ª–µ–¥—É—é—â–∏–µ —à–∞–≥–∏:

1. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –≤–µ—Ä—Å–∏—é CUDA:
   ```bash
   nvcc --version
   ```

2. –ü–µ—Ä–µ—É—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ PyTorch —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π –Ω—É–∂–Ω–æ–π –≤–µ—Ä—Å–∏–∏ CUDA:
   ```bash
   pip uninstall torch torchvision
   pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121
   ```

<details>
<summary><b>–°–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å –≤–µ—Ä—Å–∏–π CUDA –∏ PyTorch</b></summary>

| CUDA Version | PyTorch Command |
|--------------|-----------------|
| CUDA 12.8    | `pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121` |
| CUDA 12.1    | `pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121` |
| CUDA 11.7    | `pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu117` |
| CUDA 11.3    | `pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu113` |
| CUDA 10.2    | `pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu102` |

</details>

### 2. –ù–∞—Å—Ç—Ä–æ–π–∫–∞ Whisper

–í —Ñ–∞–π–ª–µ `speech_to_text.py` –Ω–∞—Å—Ç—Ä–æ–π—Ç–µ –∏—Å–ø–æ–ª—å–∑—É–µ–º—É—é –º–æ–¥–µ–ª—å Whisper:

```python
model = whisper.load_model("large-v3-turbo", device="cuda")
```

<details>
<summary><b>–î–æ—Å—Ç—É–ø–Ω—ã–µ –º–æ–¥–µ–ª–∏ Whisper</b></summary>

- **tiny**: –°–∞–º–∞—è –∫–æ–º–ø–∞–∫—Ç–Ω–∞—è –º–æ–¥–µ–ª—å —Å –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–π —Ç–æ—á–Ω–æ—Å—Ç—å—é –∏ –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π —Å–∫–æ—Ä–æ—Å—Ç—å—é
- **base**: –ù–µ–±–æ–ª—å—à–∞—è –º–æ–¥–µ–ª—å —Å –±–∞–∑–æ–≤–æ–π —Ç–æ—á–Ω–æ—Å—Ç—å—é
- **small**: –°—Ä–µ–¥–Ω—è—è –º–æ–¥–µ–ª—å —Å —Ö–æ—Ä–æ—à–∏–º –±–∞–ª–∞–Ω—Å–æ–º —Å–∫–æ—Ä–æ—Å—Ç–∏ –∏ —Ç–æ—á–Ω–æ—Å—Ç–∏
- **medium**: –ü—Ä–æ–¥–≤–∏–Ω—É—Ç–∞—è –º–æ–¥–µ–ª—å –¥–ª—è —Å–ª–æ–∂–Ω—ã—Ö –∑–∞–¥–∞—á —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è
- **large-v2**: –ö—Ä—É–ø–Ω–∞—è –º–æ–¥–µ–ª—å —Å –≤—ã—Å–æ–∫–æ–π —Ç–æ—á–Ω–æ—Å—Ç—å—é (2022)
- **large-v3**: –£–ª—É—á—à–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è —Å –ø–æ–≤—ã—à–µ–Ω–Ω–æ–π —Ç–æ—á–Ω–æ—Å—Ç—å—é
- **large-v3-turbo**: –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è –¥–ª—è –±—ã—Å—Ç—Ä–æ–π —Ä–∞–±–æ—Ç—ã (—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –¥–ª—è RTX 3070 Ti)

</details>

### 3. –ù–∞—Å—Ç—Ä–æ–π–∫–∞ OpenAI API

1. –£–∫–∞–∂–∏—Ç–µ –≤–∞—à –∫–ª—é—á OpenAI API –≤ —Ñ–∞–π–ª–µ `speech_to_text.py` (—Å—Ç—Ä–æ–∫–∞ 35)
2. –í—ã–±–µ—Ä–∏—Ç–µ –ø—Ä–µ–¥–ø–æ—á—Ç–∏—Ç–µ–ª—å–Ω—É—é –º–æ–¥–µ–ª—å:
   ```python
   model="gpt-4o-mini"  # –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –¥–ª—è –±–æ–ª—å—à–∏–Ω—Å—Ç–≤–∞ –∑–∞–¥–∞—á
   ```

### 4. –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ø—Ä–æ–º–ø—Ç–∞

–û—Ç—Ä–µ–¥–∞–∫—Ç–∏—Ä—É–π—Ç–µ –ø—Ä–æ–º–ø—Ç –ø–æ–¥ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—É—é –¥–æ–ª–∂–Ω–æ—Å—Ç—å:

```python
{"role": "system", "content": "–ü—Ä–æ–≤–æ–¥–∏—Ç—Å—è —Å–æ–±–µ—Å–µ–¥–æ–≤–∞–Ω–∏–µ –Ω–∞ –¥–æ–ª–∂–Ω–æ—Å—Ç—å ***–î–æ–ª–∂–Ω–æ—Å—Ç—å***, —Ç—ã –¥–æ–ª–∂–µ–Ω –æ—Ç–≤–µ—á–∞—Ç—å –Ω–∞ –≤–æ–ø—Ä–æ—Å—ã –∫—Ä–∞—Ç–∫–æ –∏ –ø–æ–Ω—è—Ç–Ω–æ. –ù–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ. –¢—ã –Ω–µ –¥–æ–ª–∂–µ–Ω –∑–∞–¥–∞–≤–∞—Ç—å –≤–æ–ø—Ä–æ—Å—ã, —Ç–æ–ª—å–∫–æ –æ—Ç–≤–µ—á–∞—Ç—å –Ω–∞ –Ω–∏—Ö"},
{"role": "user", "content": f"–û–±—Ä–∞–±–æ—Ç–∞–π —Å–ª–µ–¥—É—é—â–∏–π —Ç–µ–∫—Å—Ç, –æ–Ω –º–æ–∂–µ—Ç —Å–æ–¥–µ—Ä–∂–∞—Ç—å –æ—à–∏–±–∫–∏, –∏–≥–Ω–æ—Ä–∏—Ä—É–π –∏—Ö, –∏–ª–∏ –¥–æ–¥—É–º–∞–π –æ—Ç–≤–µ—Ç: {text}"}
```

### 5. –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ø–µ—Ä–µ—Ö–≤–∞—Ç–∞ –∑–≤—É–∫–∞

1. –ó–∞–≥—Ä—É–∑–∏—Ç–µ –∏ —É—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ [VB-Audio CABLE](https://vb-audio.com/Cable/)

2. **–ü–æ–¥—Ä–æ–±–Ω–∞—è –Ω–∞—Å—Ç—Ä–æ–π–∫–∞:**
   1. –©–µ–ª–∫–Ω–∏—Ç–µ –ø—Ä–∞–≤–æ–π –∫–Ω–æ–ø–∫–æ–π –º—ã—à–∏ –ø–æ –∏–∫–æ–Ω–∫–µ –∑–≤—É–∫–∞ –≤ —Ç—Ä–µ–µ –∏ –≤—ã–±–µ—Ä–∏—Ç–µ "–û—Ç–∫—Ä—ã—Ç—å –º–∏–∫—à–µ—Ä –≥—Ä–æ–º–∫–æ—Å—Ç–∏"
   2. –í—ã–±–µ—Ä–∏—Ç–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ, –æ—Ç–∫—É–¥–∞ –Ω—É–∂–Ω–æ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç—å –∑–∞–ø–∏—Å—å (Telegram/Zoom/–±—Ä–∞—É–∑–µ—Ä –∏ —Ç.–¥.)
      - –ù–∞ –ø—Ä–∏–º–µ—Ä–µ Google Chrome: –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ, —á—Ç–æ–±—ã –æ—Ç—Ç—É–¥–∞ –∏—Å—Ö–æ–¥–∏–ª –∑–≤—É–∫ (–≤–∫–ª—é—á–∏—Ç–µ –≤–∏–¥–µ–æ –∏–ª–∏ –º—É–∑—ã–∫—É)
      - –£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ –≤—ã–≤–æ–¥–∞: CABLE Input
      - –£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ –≤–≤–æ–¥–∞: –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
   
   3. –ß—Ç–æ–±—ã –ø—Ä–æ–¥–æ–ª–∂–∞—Ç—å —Å–ª—ã—à–∞—Ç—å –∑–≤—É–∫:
      - –©–µ–ª–∫–Ω–∏—Ç–µ –ø—Ä–∞–≤–æ–π –∫–Ω–æ–ø–∫–æ–π –º—ã—à–∏ –ø–æ –∏–∫–æ–Ω–∫–µ –∑–≤—É–∫–∞ –≤ —Ç—Ä–µ–µ
      - –í—ã–±–µ—Ä–∏—Ç–µ "–ü–∞—Ä–∞–º–µ—Ç—Ä—ã –∑–≤—É–∫–∞" ‚Üí –≤ —Å–∞–º–æ–º –Ω–∏–∑—É "–î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∑–≤—É–∫–∞"
      - –ü–µ—Ä–µ–π–¥–∏—Ç–µ –Ω–∞ –≤–∫–ª–∞–¥–∫—É "–ó–∞–ø–∏—Å—å" ‚Üí "CABLE Output" ‚Üí "–ü—Ä–æ—Å–ª—É—à–∞—Ç—å"
      - –ü–æ—Å—Ç–∞–≤—å—Ç–µ –≥–∞–ª–æ—á–∫—É "–ü—Ä–æ—Å–ª—É—à–∏–≤–∞—Ç—å —Å –¥–∞–Ω–Ω–æ–≥–æ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞" –∏ –≤—ã–±–µ—Ä–∏—Ç–µ —Å–≤–æ–∏ –Ω–∞—É—à–Ω–∏–∫–∏/–¥–∏–Ω–∞–º–∏–∫–∏
      - –ü–æ—Å–ª–µ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è –Ω–∞—Å—Ç—Ä–æ–µ–∫ –≤—ã –¥–æ–ª–∂–Ω—ã —Å–ª—ã—à–∞—Ç—å –∑–≤—É–∫–∏ —Å –±—Ä–∞—É–∑–µ—Ä–∞

3. **–ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–∞–±–æ—Ç—ã:**
   - –ü–æ—Å–ª–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –≤–µ—Ä–Ω–∏—Ç–µ—Å—å –∫ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—é CrackTheInterview
   - –¢–µ–ø–µ—Ä—å –≤—ã –¥–æ–ª–∂–Ω—ã –≤–∏–¥–µ—Ç—å –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–π –∑–≤—É–∫ –≤ –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–µ
   - –ü—Ä–∏ –≤—ã–¥–µ–ª–µ–Ω–∏–∏ —Ç–µ–∫—Å—Ç–∞ —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω–Ω–æ–π —Ä–µ—á–∏, –≤ –ø—Ä–∞–≤–æ–º –æ–∫–Ω–µ –ø–æ—è–≤–∏—Ç—Å—è –æ—Ç–≤–µ—Ç –æ—Ç GPT

## üîç –£—Å—Ç—Ä–∞–Ω–µ–Ω–∏–µ –Ω–µ–ø–æ–ª–∞–¥–æ–∫

- **–ù–∏–∑–∫–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è**: –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –º–æ–¥–µ–ª—å –±–æ–ª—å—à–µ–≥–æ —Ä–∞–∑–º–µ—Ä–∞ –∏–ª–∏ —É–ª—É—á—à–∏—Ç–µ –∫–∞—á–µ—Å—Ç–≤–æ –∑–≤—É–∫–∞
- **–ú–µ–¥–ª–µ–Ω–Ω–∞—è —Ä–∞–±–æ—Ç–∞**: –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è GPU (`device="cuda"`)
- **–û—à–∏–±–∫–∏ —É—Å—Ç–∞–Ω–æ–≤–∫–∏**: –ü—Ä–æ–≤–µ—Ä—å—Ç–µ —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å –≤–µ—Ä—Å–∏–π CUDA –∏ PyTorch

## üíñ –ü–æ–¥–¥–µ—Ä–∂–∫–∞ –ø—Ä–æ–µ–∫—Ç–∞

–ï—Å–ª–∏ –≤–∞–º –Ω—Ä–∞–≤–∏—Ç—Å—è –ø—Ä–æ–µ–∫—Ç, –≤—ã –º–æ–∂–µ—Ç–µ –ø–æ–¥–¥–µ—Ä–∂–∞—Ç—å —Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫–∞:

- **USDT TRC20**: `TCpmyqG8Df4SaKhinXFqfSgbmmGQw5b66K`
- **BTC**: `14nZsN8H2iWFRRHszHZRp6bk1nCxodnSZ9`

---

